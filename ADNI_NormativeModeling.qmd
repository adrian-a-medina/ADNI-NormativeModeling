---
title: "From Norms to Neuropsychopathology: Exploring Neuroanatomical & Neuropsychiatric Variation in Alzheimer’s Disease Through Normative Modeling"
subtitle: "This study extends analyses conducted by <a href='https://www.neurology.org/doi/10.1212/WNL.0000000000207298'>Verdi et al. (2023)</a>, who utilized normative modeling techniques to delineate neuroanatomical heterogeneity in Alzheimer's disease. We employ a similar methodological framework to supplement these insights by integrating both structural MRI data and neuropsychiatric symptom profiles. This integration allowed us to explore more deeply the neuroanatomical and neuropsychiatric underpinnings of Alzheimer's disease across different phenotypes within our ADNI subset. This study was conducted by the <a href='https://www.mcleanmri.org/ansl.html'>Applied Neuroimaging Statistics Ressearch Laboratory</a> at McLean Hospital & Harvard Medical School."
format:
  lumo-html: 
    logo: "Brain Logo.png"
    github-repo: "https://www.github.com/adrian-a-medina/ADNI_NormativeModeling"
    primary-color: "#a31f37"
    self-contained: true
    is-particlejs-enabled: true
    code-summary: "Expand Code"
    favicon: "https://raw.githubusercontent.com/adrian-a-medina/ADNI_NormativeModeling/main/Logo_Favicon.svg"
author: Adrián Medina
date: last-modified
---

# Project Overview

------------------------------------------------------------------------

[**Analytic Background**]{.underline}**:\
**Our study data were a subset derived from the Alzheimer's Disease Neuroimaging Initiative (ADNI) ADNI3 wave data bank. This was due to the harmonization of scanner sequence protocols across data collection sites that began during this wave. We only included subjects that had both structural MRI and PET (amyloid) data collected, followed by QA of these data. This analysis leveraged a normative model developed by the Predictive Clinical Neuroscience Group at the Donders Institute and Radboud UMC, which aims to predict and stratify brain disorders on the basis of neuroimaging data. Specifically, we used 'HBR_lifespan_36K_79sites', which makes use of the Hierarchical Bayesian Regression algorithm trained on 37,128 subjects from 79 different collection sites, across the human lifespan.

::: callout-note
Please refer to the Group's [Normative Modeling Graphical User Interface (GUI)](https://pcnportal.dccn.nl/) for more information. For reference to the template Python code used to calculate the deviation scores, please look at the Group's [Braincharts GUI](https://pcntoolkit.readthedocs.io/en/latest/pages/apply_normative_models.html).
:::

[**Considerations**]{.underline}:\
Ideally, both adaptation and testing sets would be balanced by age, sex, and site (covariates) following something like a 60/40 or 70/30 split of healthy controls. **However**, given our limited sample size, we decided to keep all of our healthy control and patient data **isolated**.

*In our analysis*: The **adaptation set** is used to calibrate for site (**only** [healthy controls]{.underline}) while the **testing set** is used **exclusively** for [patient-phenotyped data]{.underline}. Healthy control phenotypes include 'A-C-' (amyloid *negative*, cognitive impairment *negative*) & 'A+C-' (amyloid *positive*, cognitive impairment *negative*).

Patient-phenotypes include 'A+C+' (amyloid *positive*, cognitive impairment *positive*) & 'A-C+' (amyloid *negative*, cognitive impairment *positive*). As a consequence of both a smaller sample size & larger site numbers (59 sites), our group elected to utilize the MRI manufacturer (3 total) of the subject's imaging data to act as a pseudo `site` variable thus giving more power to viably calibrate for potential "site" influences.\
- `1` = `GE`\
- `2` = `Philips`\
- `3` = `Siemens`

# Code Workflow {#code-workflow}

------------------------------------------------------------------------

1.  [Data Frame Initialization](#data-frame-initialization)

::: callout-important
Some manual edits may be needed to match your imaging variables to the column headers listed in the normative model CSV template (listed in the [Normative Modeling GUI](https://pcnportal.dccn.nl/)). Specifically, go to `Compute here!` menu bar \> `Data type`, select **ThickAvg** \> `Normative Model`, select **HBR_lifespan_36K_79sites** \> wait a moment, and the site will populate the line "**Download template csv file here.**"
:::

2.  [Covariate Distributions, Data Splitting, & Balance Verification](#covariate-distributions-data-splitting-balance-verification)

::: callout-note
Upon completion of this step, you are then able to run your adaptation and testing data sets through the normative model deviation scores computation via either the [Normative Modeling GUI](https://pcnportal.dccn.nl/) or [Braincharts GUI](https://pcntoolkit.readthedocs.io/en/latest/pages/apply_normative_models.html) if you want to recreate the Python code yourself.
:::

3.  [Analytic Data Preparation](#analytic-data-preparation)
4.  [Demographic Descriptives and Statistical Analysis of Cortical Thickness](#demographic-descriptives-and-statistical-analysis-of-cortical-thickness)
5.  [Regional Analyses: Across-Groups & Pairwise Comparisons](#regional-analyses-across-groups-pairwise-comparisons)
6.  [ADNI vs PDC Preliminary Analyses](#adni-pdc)
7.  [Session Information](#session-information)

# Data Frame Initialization {#data-frame-initialization}

------------------------------------------------------------------------

Set up the R environment for neuroimaging data analysis by specifying CRAN and ggseg repositories and managing package installations with pacman. Load essential libraries and set a working directory to access neuroimaging and demographic datasets, which are then read and prepared for analysis, focusing on group cortical thickness comparisons and deviation score analyses. Rename the 'BioMarkers' variable to 'phenotype' across datasets for consistent terminology.

::: callout-tip
Front-loading the reading-in of all datasets being used in comprehensive analyses at the beginning of your script ensures that the data environment is consistently prepared, which simplifies the replication and validation process for other users.
:::

```{r Preliminary Setup, message=FALSE, warning=FALSE}
# Set CRAN repository for consistent package installation, ggseg for neuroimaging visualizations
options(repos = c(
  ggseg = 'https://ggseg.r-universe.dev',
  CRAN = 'https://cloud.r-project.org'))

# Install and load the pacman package for efficient package management
if (!require(pacman)) install.packages("pacman")
library(pacman)

# Use p_load function to install (if necessary) and load packages
p_load(dplyr, knitr, kableExtra, psych, tidyr, readr, stringr, matrixStats, ggseg, ggseg3d, 
       ggsegExtra, ggsegDesterieux, cowplot, data.table, e1071, ggplot2, plot.matrix, proxy, 
       RPMG, broom, gridExtra, patchwork, caret, tidyverse, fastDummies, sjPlot, ggbeeswarm, 
       lavaan, caTools, bitops, effects, ggeffects, reshape2, ggpubr)

# Specify the 'base_path' where you can find your data files, ASSUMING they're in the same directory, & set it as WD
base_path <- "~/GitHub/ADNI_NormativeModeling/data_files"
setwd(base_path)

# Read in foundational data set
ADNI_274_Merged <- read_csv("ADNI_274_Merged.csv") # <1>

### FreeSurfer variables were edited manually to match PCN template # <2>
### Covariates: 'age', 'sex', 'site'
# Read in finalized file, to be used ONLY for group cortical thickness comparisons (not deviation score analyses)
df_merged <- read_csv("ADNI_274_Merged_Final.csv") # <3>

# Read in computed deviation scores (the file you get back after uploading adaptation and testing sets)
df <- read_csv("ADNI_deviation_scores_BLR.csv") # <4>

# Read in PDC deviation data sets
PDC_HBR <- read_csv("PDC_HBR.csv")
PDC_BLR <- read_csv("PDC_BLR.csv")

# Rename biomarker variable to phenotype
ADNI_274_Merged <- dplyr::rename(ADNI_274_Merged, phenotype = "BioMarkers")
df_merged <- dplyr::rename(df_merged, phenotype = "BioMarkers")
df <- dplyr::rename(df, phenotype = "BioMarkers")

```

1.  For reference, this merged data file is composed of two data sets: `NIDP_DX_Dem_NP_MRI.csv` contains clinical/non-imaging variables and MRI manufacturer information, & `ADNI_lh_rh_thickness_subcort_volumes.csv` contains the FreeSurfer brain thickness measures.
2.  See details under the `important` callout in the [Code Workflow](#code-workflow) section.
3.  This should be the spreadsheet that will be split into adaptation and testing sets for normative modeling.
4.  This dataset contains subject FreeSurfer variable deviation scores for your **TESTING** set used in the Normative Modeling GUI/code.

Load and prepare Destrieux atlas data for visualization and analysis. The data from the `ggseg` package, corrected for the correct spelling of Destrieux, is assigned to variables for easy access and plotted to verify the structure and detail of the atlas features and labeled regions.

::: callout-caution
The `ggseg` package adds an extra 'e' in the spelling of the name Destrieux, so it's NOT a typo.
:::

```{r Preparing the Destrieux Atlas ROI Variables, message=FALSE, warning=FALSE}
setwd(base_path)

# Assign atlas data to data frames in local environment
desterieux_dims <- desterieux$data
desterieux <- desterieux

# Plot simple atlas features to test data frame with dimension data
plot(desterieux_dims) +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 7)) +
  guides(fill = guide_legend(ncol = 3))

# Plot atlas ROIs with labels to test data frame with complete vectors
ggplot() +
  geom_brain(atlas = desterieux)

```

# Covariate Distributions, Data Splitting, & Balance Verification {#covariate-distributions-data-splitting-balance-verification}

------------------------------------------------------------------------

Visualize and analyze the distribution of MRI manufacturers and models within the dataset after renaming the biomarker variable to phenotype. Bar plots display counts of MRI manufacturers and models grouped by manufacturer, with additional cross-tabulation bar plots showing the number of subjects by phenotype across different sites.

```{r Phenotype-Site Cross Tabulation Visualizations, message=FALSE, warning=FALSE}
# Create a bar plot for MRI manufacturers with counts displayed
ggplot(ADNI_274_Merged, aes(x = MRI_MANU)) +
  geom_bar(stat = "count", fill = "skyblue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
  labs(title = "Count of MRI Manufacturers", x = "MRI Manufacturer", y = "Count") +
  theme_minimal()

# Create separate bar plots for each manufacturer
ggplot(ADNI_274_Merged, aes(x = MRI_MAKE, fill = MRI_MANU)) +
  geom_bar(position = "dodge") +
  geom_text(aes(label = ..count..), stat = "count", position = position_dodge(width = 0.9), vjust = -0.5) +
  facet_wrap(~MRI_MANU, scales = "free_x") +
  labs(title = "Counts of Each MRI Make Grouped by Manufacturer", x = "MRI Make", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better visibility

# Counting subjects by phenotype within each site
phenotype_site_counts <- df_merged %>%
  group_by(site, phenotype) %>%
  dplyr::summarise(Count = n(), .groups = 'drop')

# Plot with Site on x-axis
plot_site_x <- ggplot(phenotype_site_counts, aes(x = site, y = Count, fill = phenotype)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = Count), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(title = "Subject Counts by Phenotype Across Sites",
       x = "Site",
       y = "Number of Subjects",
       fill = "Phenotype") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))

# Plot with Phenotype on x-axis
plot_phenotype_x <- ggplot(phenotype_site_counts, aes(x = phenotype, y = Count, fill = factor(site))) +
  geom_bar(stat = "identity", position = position_dodge()) +  # Use position_dodge() for proper grouping
  geom_text(aes(label = Count), vjust = -0.5, position = position_dodge(width = 0.9)) +  # Adjust text positioning
  labs(title = "Subject Counts Across Phenotype by Site",
       x = "Phenotype",
       y = "Number of Subjects",
       fill = "Site") +
  scale_fill_brewer(palette = "Set1") +  # Using a qualitative palette for distinct sites
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))  # Improve readability of x-axis labels

# Optionally, print both plots to view them in the R environment
print(plot_site_x)
print(plot_phenotype_x)

```

Create adaptation and testing datasets from the merged data based on specific biomarker criteria, setting aside the groups for separate analyses. The datasets are saved as CSV files, which will be used for further normative model computations after ensuring that the data are balanced in terms of covariates and grouping variables.

```{r Re-Creating Testing & Adaptation Datasets with Updated Site, message=FALSE, warning=FALSE}
# Separate the data based on 'phenotype'
adaptation_data <- df_merged %>%
  filter(phenotype %in% c("A-C-", "A+C-"))

testing_data <- df_merged %>%
  filter(phenotype %in% c("A-C+", "A+C+"))

# Save the adaptation and testing datasets as CSV files, un-comment when verified
# write_csv(adaptation_data, "ADNI_175_Adaptation.csv")
# write_csv(testing_data, "ADNI_99_Testing.csv")

```

::: callout-note
After verifying that the grouping variable and covariates are balanced as desired (i.e., see the next chunk), you can now run them through the normative model computation via the GUI or recreate their code yourself!
:::

Generate visualizations to assess the balance of biomarkers, site, and sex distributions in adaptation and testing datasets, and calculate the average age for each dataset. These plots and summaries ensure the datasets are appropriately balanced before further normative model computations.

```{r Creating Plots to Visualize Dataset Balance Across Split, message=FALSE, warning=FALSE}
# Plotting the distribution of 'BioMarkers' in both datasets
biomarker_distribution <- bind_rows(
  mutate(adaptation_data, dataset = "Adaptation"),
  mutate(testing_data, dataset = "Testing")
) %>%
  group_by(dataset, phenotype) %>%
  dplyr::summarise(Count = n(), .groups = 'drop') %>%
  group_by(dataset) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

ggplot(biomarker_distribution, aes(x = phenotype, y = Percentage, fill = dataset)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Distribution of Biomarker", x = "Biomarker", y = "Percentage (%)") +
  theme_minimal()

# Plotting the distribution of 'site' in both datasets
site_distribution <- bind_rows(
  mutate(adaptation_data, dataset = "Adaptation"),
  mutate(testing_data, dataset = "Testing")
) %>%
  group_by(dataset, site) %>%
  dplyr::summarise(Count = n(), .groups = 'drop') %>%
  group_by(dataset) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

ggplot(site_distribution, aes(x = site, y = Percentage, fill = dataset)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Distribution of Site", x = "Site", y = "Percentage (%)") +
  theme_minimal()

# Plotting the distribution of 'sex' in both datasets
sex_distribution <- bind_rows(
  mutate(adaptation_data, dataset = "Adaptation"),
  mutate(testing_data, dataset = "Testing")
) %>%
  group_by(dataset, sex) %>%
  dplyr::summarise(Count = n(), .groups = 'drop') %>%
  group_by(dataset) %>%
  mutate(Percentage = (Count / sum(Count)) * 100)

ggplot(sex_distribution, aes(x = sex, y = Percentage, fill = dataset)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Distribution of Sex", x = "Sex", y = "Percentage (%)") +
  theme_minimal()

# Calculating and comparing the average age
age_summary <- bind_rows(
  mutate(adaptation_data, dataset = "Adaptation"),
  mutate(testing_data, dataset = "Testing")
) %>%
  group_by(dataset) %>%
  dplyr::summarise(Average_Age = mean(age, na.rm = TRUE), .groups = 'drop')

print(age_summary)

```

# Analytic Data Preparation {#analytic-data-preparation}

------------------------------------------------------------------------

Reorganize and recode key variables in the dataset for group cortical thickness comparisons: set the column order for clarity, recode the 'phenotype' variable to categorical levels representing health conditions, and standardize categorical labels for 'site' and 'sex' to enhance readability and analysis consistency.

```{r Recoding & Reorganizing Analytic Variables for ONLY Group Cortical Thickness Comparisons, message=FALSE, warning=FALSE}
# Specifying the order of the first few columns for easier viewing
desired_order <- c("Subject_ID", "age", "sex", "site", "phenotype")

# Append the remaining column names that are not specified in desired_order
remaining_cols <- setdiff(names(df_merged), desired_order)

# Combine the specified order with the remaining columns
new_order <- c(desired_order, remaining_cols)

# Reorder the columns in df according to new_order
df_merged <- df_merged[, new_order]

# Recode phenotype variable
df_merged$phenotype <- recode(df_merged$phenotype,
                              "A-C-" = "HC",
                              "A+C-" = "HC",
                              "A-C+" = "MCI",
                              "A+C+" = "AD")
df_merged$phenotype <- as.factor(df_merged$phenotype)
df_merged$phenotype <- factor(df_merged$phenotype, levels = c("HC", "MCI", "AD")) # explicitly set the reference level

# Recode site variable
df_merged$site <- gsub("1", "GE", df_merged$site)
df_merged$site <- gsub("2", "Philips", df_merged$site)
df_merged$site <- gsub("3", "Siemens", df_merged$site)
df_merged$site <- as.factor(df_merged$site)

# Recode sex variable, 0 = females 1 = males
df_merged$sex <- gsub("0", "Female", df_merged$sex)
df_merged$sex <- gsub("1", "Male", df_merged$sex)
df_merged$sex <- factor(df_merged$sex)

```

# Demographic Descriptives and Statistical Analysis of Cortical Thickness {#demographic-descriptives-and-statistical-analysis-of-cortical-thickness}

------------------------------------------------------------------------

Generate descriptive statistics and visualize the distribution of key variables such as phenotype, age, and sex within the dataset. Employ cross-tabulation to analyze mean cortical thickness and age by phenotype group, and present these distributions using violin and bar plots. Additionally, compute summary statistics for mean cortical thickness and visually represent them using rain cloud plots to highlight differences across phenotype groups.

```{r Descriptive Statistics by Variable, message=FALSE, warning=FALSE}
# Count of each variable of interest
table(df_merged$phenotype)
table(df_merged$sex)
table(df_merged$site)

# Cross-Tabulation of average thickness and phenotype group
describeBy(df_merged$Mean_Thickness, df_merged$phenotype)
d<-(describeBy(df_merged$Mean_Thickness, df_merged$phenotype))

# Cross-Tabulation of age and phenotype group
describeBy(df_merged$age, df_merged$phenotype)
mean(df_merged$age)
sd(df_merged$age)

# Generate the violin plot of age stratified by phenotype categories
ggplot(df_merged, aes(x = phenotype, y = age, fill = phenotype)) +
  geom_violin() +
  labs(title = "Distribution of Age Stratified by Phenotype Groups",
       x = "Phenotype Group", y = "Age") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))  # Improve readability of x-axis labels

# Cross-Tabulation of sex & phenotype, visualization
ggplot(df_merged, aes(x = phenotype, fill = sex)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of Sex Across Phenotype Groups",
       x = "Phenotype Group",
       y = "Count",
       fill = "Sex") +
  theme_minimal()

# Create the summary Mean_Thickness data frame
filtered_MT_summary <- df_merged %>%
  group_by(phenotype) %>%
  dplyr::summarise(
    score_mean = mean(Mean_Thickness, na.rm = TRUE),
    n = n(), # Sample size for each group
    sem = sd(Mean_Thickness, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Create the rain cloud plot with separate components
ggplot(df_merged, aes(x = phenotype, y = Mean_Thickness, fill = phenotype, color = phenotype)) +
  PupillometryR::geom_flat_violin(adjust = 1.5, trim = FALSE, alpha = 0.5, position = position_nudge(x = 0.2, y = 0), colour = NA) +
  geom_point(aes(x = as.numeric(phenotype)-0.25, y = Mean_Thickness, colour = phenotype), position = position_jitter(width = .05), size = .5, shape = 20) +
  geom_boxplot(outlier.shape = NA, alpha = 0.5, width = 0.25, position = position_dodge(width = 0.3), colour = "black") +
  geom_point(data = filtered_MT_summary, aes(x = factor(phenotype), y = score_mean), shape = 18, position = position_nudge(x = 0.2)) +
  geom_errorbar(data = filtered_MT_summary, aes(x = factor(phenotype), y = score_mean, ymin = score_mean - sem, ymax = score_mean + sem), width = 0.05, position = position_nudge(x = 0.2)) +
  labs(
    title = "Distribution of Mean Cortical Thickness Stratified by Phenotype Groups", 
    y = "Score", 
    x = "Phenotype", 
    fill = "Phenotype Group",  # Legend title for fill
    color = "Phenotype Group"  # Legend title for color
  ) +
  theme_minimal() +
  theme(
    legend.position = "right",
    legend.title = element_text(face = "bold")  # Make legend title bold
  )

```

Model the impact of phenotype on mean cortical thickness using linear regression, adjusting for covariates such as age and sex. Visualize these relationships and conduct Tukey's HSD tests to identify significant differences between phenotype groups, presenting results in both tabular form and through a significance plot of the Tukey HSD test outcomes.

```{r Cortical Thickness Modeling, message=FALSE, warning=FALSE, results='asis'}
# Fit a linear model of Mean_Thickness as a function of phenotype and store it in s_2
s_2 <- lm(Mean_Thickness ~ phenotype, data = df_merged)

# Create a table for the linear model with confidence intervals
tab_model(s_2, title = "Linear Model: Average Cortical Thickness as a Function of Phenotype")

# Perform Tukey's Honest Significant Difference test and store results
tukey_results_s2 <- TukeyHSD(aov(Mean_Thickness ~ phenotype, data = df_merged))
print(tukey_results_s2)
tukey_data_s2 <- as.data.frame(tukey_results_s2$phenotype)
tukey_data_s2$Comparison <- rownames(tukey_data_s2)
tukey_data_s2$significant <- ifelse(tukey_data_s2$`p adj` < 0.05, "Significant", "Not Significant")

# Creating the plot of the Tukey HSD test with significance indication
ggplot(tukey_data_s2, aes(y = Comparison, xmin = lwr, xmax = upr, x = diff)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_errorbarh(aes(height = 0.2, color = significant)) +
  geom_point(aes(x = diff, color = significant), size = 2) +
  scale_color_manual(values = c("Significant" = "red", "Not Significant" = "blue")) +
  labs(title = "Tukey HSD Test Results for Mean Cortical Thickness by Phenotype",
       x = "Differences in Mean Levels of Phenotype",
       y = "Comparison",
       color = "P-value Significance") +
  theme_minimal()

# Fit a linear model of Mean_Thickness as a function of phenotype with added covariates
s_1<-lm(Mean_Thickness ~ phenotype + age + sex, data = df_merged)

# Create a table for the linear model including covariates with confidence intervals
tab_model(s_1, title = "Enhanced Linear Model: Average Cortical Thickness as a Function of Phenotype, Adjusted for Age and Sex")

# Plot multiple regression model
ggpredict(s_1, c(terms = "age", "phenotype", "sex")) |>
  plot() +
  labs(title = "Average Cortical Thickness as a Function of Phenotype, Adjusted for Age and Sex",
       x = "Age",
       y = "Mean Cortical Thickness (mm)",
       caption = "Note: 'phenotype' factors, 'HC' = Healthy Control; 'MCI' = Mild Cognitive Impairment; & 'AD' = Alzheimer's Disease.")

```

# Regional Analyses: Across-Groups & Pairwise Comparisons {#regional-analyses-across-groups-pairwise-comparisons}

------------------------------------------------------------------------

Conduct ANOVA to assess differences across phenotype groups in brain regions' FreeSurfer volume measures, then apply False Discovery Rate (FDR) corrections to p-values and calculate F-statistics. Finally, visualize significant regions using a heatmap, categorizing results by significance levels, and incorporating annotations for clearer demarcation of significance groups.

```{r Across-Groups Comparisons, message=FALSE, warning=FALSE}
# Apply suffix to all ROI FreeSurfer measures
df.rois <- df_merged %>% rename_at(vars((6:153)), ~ paste0(., '_rois'))

# Run ANOVA analyses for each ROI across phenotype group and extract just the p-values
df.stats <- as.data.frame(sapply(X = df.rois[,grep("_rois", names(df.rois),value = T)], FUN = function(x) summary(aov(x ~ df.rois$phenotype))[[1]][["Pr(>F)"]][1]))

# Rename columns in ANOVA output data frame
names(df.stats) <- "p_value"
setDT(df.stats, keep.rownames = "ROI")

# Verify that changes were made via the first 20 ROIs
head(df.stats, 20)

# Run False Discovery Rate (FDR) corrections 
df.stats <- cbind(df.stats, p.adjust(df.stats$p_value), method = "fdr")

# Rename column of FDR-corrected p-values
names(df.stats)[3] <- "FDR.pvalue"

# Verify that changes were made
head(df.stats, 20)

### Repeat steps to now obtain the F-stat values
# Run ANOVA analyses for each ROI across phenotype group and extract just the F-stat values
df.f_stats <- as.data.frame(sapply(X = df.rois[,grep("_rois", names(df.rois),value = T)], FUN = function(x) summary(aov(x ~ df.rois$phenotype))[[1]][["F value"]][1]))

# Rename columns in ANOVA output data frame
names(df.f_stats) <- "f_stat"
setDT(df.f_stats, keep.rownames = "ROI")

# Verify that changes were made via the first 20 ROIs
head(df.f_stats, 20)

# List the ROIs that are significant after FDR correction
df.stats[which(df.stats$FDR.pvalue <0.05),]

# Assign significance levels
df.stats$Significance <- ifelse(df.stats$FDR.pvalue < 0.001, '***',
                               ifelse(df.stats$FDR.pvalue < 0.01, '**',
                               ifelse(df.stats$FDR.pvalue < 0.05, '*', '')))

# Merge data frames for visualization
df.stats_merged <- merge(df.stats, df.f_stats, by = "ROI")

# Melt the data for plotting
df.melted <- melt(df.stats_merged, id.vars = "ROI", variable.name = "Statistic", value.name = "Value")

# Ensure that 'Value' is numeric
df.melted$Value <- as.numeric(as.character(df.melted$Value))

# Ensure df.stats and df.melted are merged to filter and sort
df.melted <- df.melted %>%
  filter(Statistic == "f_stat") %>%
  left_join(df.stats %>% select(ROI, Significance, FDR.pvalue), by = "ROI") %>%
  filter(FDR.pvalue < 0.05) %>%
  arrange(match(Significance, c("", "*", "**", "***")))  # Order by significance levels

# Remove suffix from ROI list
df.melted$ROI <- gsub("_rois", "", df.melted$ROI)

# Define group positions and labels
group_positions <- data.frame(
  start = c(1, 15, 30),  # will need to adjust depending on your own results
  end = c(14, 29, 51),    # will need to adjust depending on your own results
  label = c("*", "**", "***")  # example labels for significance
)

# Create the heatmap
heatmap_plot <- ggplot(df.melted, aes(x = ROI, y = Statistic, fill = Value)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Heatmap of ANOVA Statistics Across ROIs", x = "Region of Interest", y = "F-Statistic") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Add custom brackets using annotations
for (i in 1:nrow(group_positions)) {
  heatmap_plot <- heatmap_plot +
    annotate("segment", x = group_positions$start[i], xend = group_positions$end[i], y = Inf, yend = Inf, yjust = 1.5, color = "black", size = 0.5) +
    annotate("text", x = (group_positions$start[i] + group_positions$end[i]) / 2, y = Inf, label = group_positions$label[i], vjust = 2, hjust = 0.5)
}

# Print the cutomized heatmap
print(heatmap_plot)

```

Adjust brain region names in the data to align with the **Destrieux** atlas nomenclature for both left and right hemispheres, performing extensive renaming to match the standard naming convention. This ensures the region names are compatible with established neuroimaging atlas formats for subsequent analyses.

```{r Convert Across-Groups Data to Destrieux Atlas Format, message=FALSE, warning=FALSE}
# Remove suffix from ROI list
df.stats$ROI <- as.data.frame(gsub("_rois", "", df.stats$ROI))

### Rename ROIs to assign nomenclature consistent with the 'desterieux' atlas package
# Left hemisphere ROIs
left.df.stats <- df.stats %>%
  filter(str_detect(ROI, "L_"))
x <- gsub("L_", "", left.df.stats$ROI)
y <- gsub("G&S_", "G and S ", x)
z <- gsub("G_", "G ", y)
z1 <- gsub("S_", "S ", z)
z2 <- gsub("_", " ", z1)
z3 <- gsub(" bin", "", z2)
z4 <- gsub("\\.", " ", z3)
z5 <- gsub("cingul ", "cingul-", z4)
z6 <- gsub("Mid ", "Mid-", z5)
z7 <- gsub("Post ", "Post-", z6)
z8 <- gsub("inf ", "inf-", z7)
z9 <- gsub("med ", "med-", z8)
z10 <- gsub("sup ", "sup-", z9)
z11 <- gsub("Fis ant ", "Fis-ant-", z10)
z12 <- gsub("precentral ", "precentral-", z11)
z13 <- gsub("Fis pos ", "Fis-pos-", z12)
z14 <- gsub("lg&S", "lg and S", z13)
z15 <- gsub("oc temp", "oc-temp", z14)
z16 <- gsub("sup and transversal", "sup-transversal", z15)
z17 <- gsub("orbital H Shaped", "orbital-H Shaped", z16)
z18 <- gsub("oc sup&transversal", "oc sup and transversal", z17)
z19 <- gsub("prim Jensen", "prim-Jensen", z18)
z20 <- gsub("S oc-temp med&Lingual", "S oc-temp med and Lingual", z19)
z21 <- gsub("lat fusifor", "lat-fusifor", z20)
z22 <- gsub("middle&Lunatus", "middle and Lunatus", z21)
z23 <- gsub("intrapariet&P trans", "intrapariet and P trans", z22)
renamed_ROIs <- gsub("Lat Fis post", "Lat Fis-post", z23)

desterieux_ROIs <- as.data.frame(desterieux_dims %>% filter(hemi == "left"))$region
compare_lists <- cbind(sort(renamed_ROIs), sort(unique(desterieux_ROIs)))
list_matches <- compare_lists[,1] %in% compare_lists[,2]
compare_lists[!list_matches,]

## if no mismatches, than add to data.frame as region
left.df.stats$region <- renamed_ROIs

# Right hemisphere ROIs
right.df.stats <- df.stats %>%
  filter(str_detect(ROI, "R_"))
x <- gsub("R_", "", right.df.stats$ROI)
y <- gsub("G&S_", "G and S ", x)
z <- gsub("G_", "G ", y)
z1 <- gsub("S_", "S ", z)
z2 <- gsub("_", " ", z1)
z3 <- gsub(" bin", "", z2)
z4 <- gsub("\\.", " ", z3)
z5 <- gsub("cingul ", "cingul-", z4)
z6 <- gsub("Mid ", "Mid-", z5)
z7 <- gsub("Post ", "Post-", z6)
z8 <- gsub("inf ", "inf-", z7)
z9 <- gsub("med ", "med-", z8)
z10 <- gsub("sup ", "sup-", z9)
z11 <- gsub("Fis ant ", "Fis-ant-", z10)
z12 <- gsub("precentral ", "precentral-", z11)
z13 <- gsub("Fis pos ", "Fis-pos-", z12)
z14 <- gsub("lg&S", "lg and S", z13)
z15 <- gsub("oc temp", "oc-temp", z14)
z16 <- gsub("sup and transversal", "sup-transversal", z15)
z17 <- gsub("orbital H Shaped", "orbital-H Shaped", z16)
z18 <- gsub("oc sup&transversal", "oc sup and transversal", z17)
z19 <- gsub("prim Jensen", "prim-Jensen", z18)
z20 <- gsub("S oc-temp med&Lingual", "S oc-temp med and Lingual", z19)
z21 <- gsub("lat fusifor", "lat-fusifor", z20)
z22 <- gsub("middle&Lunatus", "middle and Lunatus", z21)
z23 <- gsub("intrapariet&P trans", "intrapariet and P trans", z22)
renamed_ROIs <- gsub("Lat Fis post", "Lat Fis-post", z23)

desterieux_ROIs <- as.data.frame(desterieux_dims %>% filter(hemi == "right"))$region
compare_lists <- cbind(sort(renamed_ROIs), sort(unique(desterieux_ROIs)))
list_matches <- compare_lists[,1] %in% compare_lists[,2]
compare_lists[!list_matches,]

## if no mismatches, than add to data.frame as region
right.df.stats$region <- renamed_ROIs

```

Visualize significant FDR-corrected p-values for brain regions across groups using gradient-filled maps for both left and right hemispheres, highlighted with different colors to represent statistical significance levels. These plots are organized in a grid layout to facilitate comparison between hemispheres.

```{r Plot Significant FDR-Corrected p-Values for Across-Groups Data, message=FALSE, warning=FALSE}
# Left hemisphere
left_pvalues <- ggseg(.data=left.df.stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "left", colour = "white", size = 0.2) + 
scale_fill_gradientn(limits = c(0,0.05), colours =  rainbow.colors(5))

# Right hemisphere
right_pvalues <- ggseg(.data=right.df.stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "right", colour = "white", size = 0.2) +
  scale_fill_gradientn(limits = c(0,0.05), colours = rainbow.colors(5))

# Add titles to individual plots
left_pvalues <- left_pvalues + labs(title = "Between-Group Comparisons")
right_pvalues <- right_pvalues + labs(title = "Between-Group Comparisons")

cowplot::plot_grid(left_pvalues,right_pvalues, nrow = 2, labels = "AUTO")

```

Conduct pairwise statistical comparisons between controls and Alzheimer's disease patients on cortical thickness measures. Perform t-tests on each brain region, followed by FDR corrections to adjust for multiple comparisons, organizing the results into a clean data frame with significance levels marked.

```{r Pairwise Comparisons in Control vs AD, message=FALSE, warning=FALSE}
# Data frame preparation
df.CA <- df_merged[grep("HC|AD", df_merged$phenotype), ] # Subset just Controls and Alzheimer's ("CA")

# Perform t-test and extract t-stat value, p-value, and parameters
df.CA_stats <- as.data.frame(sapply(df.CA[6:153], function(x) t.test(x ~ df.CA$phenotype)$statistic))
df.CA_stats1 <- as.data.frame(sapply(df.CA[6:153], function(x) t.test(x ~ df.CA$phenotype)$p.value))
df.CA_stats2 <- as.data.frame(sapply(df.CA[6:153], function(x) t.test(x ~ df.CA$phenotype)$parameter))

# Merge data frames and remove the subsequent, intermediate data frames
df.CA_stats <- cbind(df.CA_stats, df.CA_stats1)
df.CA_stats <- cbind(df.CA_stats, df.CA_stats2)
rm(df.CA_stats1, df.CA_stats2)

# Clean up the t-test data frame
df.CA_stats$t_statistic <- df.CA_stats[2] # Rename column
names(df.CA_stats) <- c('statistic', 'p.value', 'parameter')
df.CA_stats[4] <- NULL

# Perform FDR correction on t-test data frame
df.CA_stats <- cbind(df.CA_stats, p.adjust(df.CA_stats$p.value), method = "fdr")
names(df.CA_stats)[4] <- "FDR.pvalue"
df.CA_stats[5] <- NULL

# Clean up the FDR-corrected data frame
df.CA_stats <- tibble::rownames_to_column(df.CA_stats, "ROI") # Create ROI column
df.CA_stats$ROI <- gsub("\\.t$", "", df.CA_stats$ROI)

# List the ROIs that are significant after FDR correction
df.CA_stats_sig <- df.CA_stats[which(df.CA_stats$FDR.pvalue <0.05),]

```

Conduct t-tests between control and MCI groups, extracting t-statistics and p-values for brain regions, followed by FDR correction to account for multiple comparisons, leading to a cleaned and organized presentation of significant regions.

```{r Pairwise Comparisons in Control vs MCI, message=FALSE, warning=FALSE}
# Data frame preparation
df.CM <- df_merged[grep("HC|MCI", df_merged$phenotype), ] # Subset just Controls and MCI ("CM")

# Perform t-test and extract t-stat value, p-value, and parameters
df.CM_stats <- as.data.frame(sapply(df.CM[6:153], function(x) t.test(x ~ df.CM$phenotype)$statistic))
df.CM_stats1 <- as.data.frame(sapply(df.CM[6:153], function(x) t.test(x ~ df.CM$phenotype)$p.value))
df.CM_stats2 <- as.data.frame(sapply(df.CM[6:153], function(x) t.test(x ~ df.CM$phenotype)$parameter))

# Merge data frames and remove the subsequent, intermediate data frames
df.CM_stats <- cbind(df.CM_stats, df.CM_stats1)
df.CM_stats <- cbind(df.CM_stats, df.CM_stats2)
rm(df.CM_stats1, df.CM_stats2)

# Clean up the t-test data frame
df.CM_stats$t_statistic <- df.CM_stats[2] # Rename column
names(df.CM_stats) <- c('statistic', 'p.value', 'parameter')
df.CM_stats[4] <- NULL

# Perform FDR correction on t-test data frame
df.CM_stats <- cbind(df.CM_stats, p.adjust(df.CM_stats$p.value), method = "fdr")
names(df.CM_stats)[4] <- "FDR.pvalue"
df.CM_stats[5] <- NULL

# Clean up the FDR-corrected data frame
df.CM_stats <- tibble::rownames_to_column(df.CM_stats, "ROI") # Create ROI column
df.CM_stats$ROI <- gsub("\\.t$", "", df.CM_stats$ROI)

# List the ROIs that are significant after FDR correction
df.CM_stats_sig <- df.CM_stats[which(df.CM_stats$FDR.pvalue <0.05),]

```

Perform pairwise t-tests between MCI and Alzheimer's groups, extracting critical statistics for comparative analysis, apply FDR corrections for multiple testing, and combine significant results to visualize in a lollipop plot, differentiating groups with colors and annotations for significance levels.

```{r Pairwise Comparisons in MCI vs AD, message=FALSE, warning=FALSE}
# Data frame preparation
df.MA <- df_merged[grep("MCI|AD", df_merged$phenotype), ] # Subset just MCI and Alzheimer's ("MA")

### MCI vs Alzheimer's t-test
# Perform t-test and extract t-stat value, p-value, and parameters
df.MA_stats <- as.data.frame(sapply(df.MA[6:153], function(x) t.test(x ~ df.MA$phenotype)$statistic))
df.MA_stats1 <- as.data.frame(sapply(df.MA[6:153], function(x) t.test(x ~ df.MA$phenotype)$p.value))
df.MA_stats2 <- as.data.frame(sapply(df.MA[6:153], function(x) t.test(x ~ df.MA$phenotype)$parameter))

# Merge data frames and remove the subsequent, intermediate data frames
df.MA_stats <- cbind(df.MA_stats, df.MA_stats1)
df.MA_stats <- cbind(df.MA_stats, df.MA_stats2)
rm(df.MA_stats1, df.MA_stats2)

# Clean up the t-test data frame
df.MA_stats$t_statistic <- df.MA_stats[2] # Rename column
names(df.MA_stats) <- c('statistic', 'p.value', 'parameter')
df.MA_stats[4] <- NULL

# Perform FDR correction on t-test data frame
df.MA_stats <- cbind(df.MA_stats, p.adjust(df.MA_stats$p.value), method = "fdr")
names(df.MA_stats)[4] <- "FDR.pvalue"
df.MA_stats[5] <- NULL

# Clean up the FDR-corrected data frame
df.MA_stats <- tibble::rownames_to_column(df.MA_stats, "ROI") # Create ROI column
df.MA_stats$ROI <- gsub("\\.t$", "", df.MA_stats$ROI)

# List the ROIs that are significant after FDR correction
df.MA_stats_sig <- df.MA_stats[which(df.MA_stats$FDR.pvalue <0.05),]

# Combine the significant results for easy plotting
combined_stats_sig <- bind_rows(
  df.CA_stats_sig %>% mutate(Comparison = "HC vs AD"),
  df.MA_stats_sig %>% mutate(Comparison = "MCI vs AD")
)

# Assign significance levels
combined_stats_sig$Significance <- ifelse(combined_stats_sig$FDR.pvalue < 0.001, '***',
                               ifelse(combined_stats_sig$FDR.pvalue < 0.01, '**',
                               ifelse(combined_stats_sig$FDR.pvalue < 0.05, '*', '')))

# Create the lollipop plot
ggplot(combined_stats_sig, aes(x = reorder(ROI, statistic), y = statistic, color = Comparison)) +
  geom_segment(aes(yend = 0, xend = ROI), size = 1, linetype = "dashed") +
  geom_point(size = 3) +
  labs(
    title = "Significant Differences in Brain Regions Across Comparisons",
    x = "Region of Interest",
    y = "T-Statistic Value",
    color = "Comparison",
    caption = "Note: 'HC' = Healthy Control; 'MCI' = Mild Cognitive Impairment; & 'AD' = Alzheimer's Disease.") +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 90, hjust = 1, size = 7.5)  # Rotate x labels for better visibility
  )

```

Define a function to rename region of interest (ROI) labels for brain imaging data to align with the Destrieux atlas nomenclature. Adjust ROI names based on hemisphere, applying systematic replacements to match atlas standards, and then check for mismatches against the atlas database, allowing for application across multiple datasets and hemispheres.

```{r Convert Pairwise Data to Destrieux Atlas Format, message=FALSE, warning=FALSE}
# Rename ROIs to assign nomenclature consistent with the desterieux atlas package # <1>
rename_rois <- function(df, hemi, desterieux_dims) {
  # Filter based on hemisphere
  hemi_prefix <- ifelse(hemi == "left", "L_", "R_")
  df_filtered <- df %>%
    filter(str_detect(ROI, hemi_prefix))
  
  # Perform renaming steps
  x <- gsub(paste0(hemi_prefix), "", df_filtered$ROI)
  patterns <- c("G&S_", "G_", "S_", "_", " bin", "\\.", "cingul ", "Mid ", "Post ", 
                "inf ", "med ", "sup ", "Fis ant ", "precentral ", "Fis pos ", "lg&S", 
                "oc temp", "sup and transversal", "orbital H Shaped", "oc sup&transversal", 
                "prim Jensen", "S oc-temp med&Lingual", "lat fusifor", "middle&Lunatus", 
                "intrapariet&P trans", "Lat Fis post")
  replacements <- c("G and S ", "G ", "S ", " ", "", " ", "cingul-", "Mid-", "Post-", 
                    "inf-", "med-", "sup-", "Fis-ant-", "precentral-", "Fis-pos-", 
                    "lg and S", "oc-temp", "sup-transversal", "orbital-H Shaped", 
                    "oc sup and transversal", "prim-Jensen", "S oc-temp med and Lingual", 
                    "lat-fusifor", "middle and Lunatus", "intrapariet and P trans", 
                    "Lat Fis-post")
  for (i in seq_along(patterns)) {
    x <- gsub(patterns[i], replacements[i], x)
  }
  
  # Match with desterieux ROIs
  desterieux_ROIs <- as.data.frame(desterieux_dims %>% filter(hemi == hemi))$region
  compare_lists <- cbind(sort(x), sort(unique(desterieux_ROIs)))
  list_matches <- compare_lists[,1] %in% compare_lists[,2]
  
  if (any(!list_matches)) {
    warning("There are mismatches in ROI names for the ", hemi, " hemisphere.")
  }
  
  df_filtered$region <- x
  return(df_filtered)
}

# Apply the function to each dataset and hemisphere
left.df.CA_stats <- rename_rois(df.CA_stats, "left", desterieux_dims)
right.df.CA_stats <- rename_rois(df.CA_stats, "right", desterieux_dims)
left.df.CM_stats <- rename_rois(df.CM_stats, "left", desterieux_dims)
right.df.CM_stats <- rename_rois(df.CM_stats, "right", desterieux_dims)
left.df.MA_stats <- rename_rois(df.MA_stats, "left", desterieux_dims)
right.df.MA_stats <- rename_rois(df.MA_stats, "right", desterieux_dims)

```

1.  Automated loop version

Visualize the significance of FDR-corrected p-values for pairwise comparisons (Control vs. Alzheimer's, Control vs. MCI, and MCI vs. Alzheimer's) across both hemispheres using the Destrieux atlas. Generate separate gradient-filled plots for each comparison and hemisphere, labeling each to reflect the specific groups compared. Display these plots using a grid layout to assess differences effectively.

```{r Plot Significant FDR-Corrected p-Values for Pairwise Data, message=FALSE, warning=FALSE}
### Control vs Alzheimer's
# Left hemisphere
left_CA_pvalues <- ggseg(.data=left.df.CA_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "left", colour = "white", size = 0.2) + 
scale_fill_gradientn(limits = c(0,0.05), colours =  rainbow.colors(5))

# Right hemisphere
right_CA_pvalues <- ggseg(.data=right.df.CA_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "right", colour = "white", size = 0.2) +
  scale_fill_gradientn(limits = c(0,0.05), colours = rainbow.colors(5))

### Control vs MCI
# Left hemisphere
left_CM_pvalues <- ggseg(.data=left.df.CM_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "left", colour = "white", size = 0.2) + 
scale_fill_gradientn(limits = c(0,0.05), colours =  rainbow.colors(5))

# Right hemisphere
right_CM_pvalues <- ggseg(.data=right.df.CM_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "right", colour = "white", size = 0.2) +
  scale_fill_gradientn(limits = c(0,0.05), colours = rainbow.colors(5))

### MCI vs Alzheimer's
# Left hemisphere
left_MA_pvalues <- ggseg(.data=left.df.MA_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "left", colour = "white", size = 0.2) + 
scale_fill_gradientn(limits = c(0,0.05), colours =  rainbow.colors(5))

# Right hemisphere
right_MA_pvalues <- ggseg(.data=right.df.MA_stats, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "right", colour = "white", size = 0.2) +
  scale_fill_gradientn(limits = c(0,0.05), colours = rainbow.colors(5))

# Add titles to individual plots
left_CA_pvalues <- left_CA_pvalues + labs(title = "Healthy Controls vs Alzheimer's Group")
right_CA_pvalues <- right_CA_pvalues + labs(title = "Healthy Controls vs Alzheimer's Group")

left_CM_pvalues <- left_CM_pvalues + labs(title = "Healthy Controls vs MCI Group")
right_CM_pvalues <- right_CM_pvalues + labs(title = "Healthy Controls vs MCI Group")

left_MA_pvalues <- left_MA_pvalues + labs(title = "MCI Group vs Alzheimer's Group")
right_MA_pvalues <- right_MA_pvalues + labs(title = "MCI Group vs Alzheimer's Group")

# Print plots to verify that they were correctly constructed
cowplot::plot_grid(left_CA_pvalues, right_CA_pvalues, nrow = 2)
cowplot::plot_grid(left_CM_pvalues, right_CM_pvalues, nrow = 2)
cowplot::plot_grid(left_MA_pvalues, right_MA_pvalues, nrow = 2)

```

# Z-Score Statistics Pipeline

------------------------------------------------------------------------

Transform and reorganize analytic variables for comprehensive analyses by converting the 'phenotype' column into dummy variables, removing superfluous columns, and systematically renaming and reordering columns for clarity. This process ensures data columns align more effectively with analytical needs, including adjusting categorical variables for models and ensuring ROI names are standardized without duplicates.

```{r Recoding & Reorganizing Analytic Variables for All Other Analyses, message=FALSE, warning=FALSE}
# Use dummy_cols to create dummy variables for the 'phenotype' column
df <- dummy_cols(df, select_columns = "phenotype", remove_first_dummy = TRUE, remove_selected_columns = TRUE)

# Rename dummy variable column back to phenotype
df <- dplyr::rename(df, phenotype = "phenotype_A+C+")

# Omit the 'index' column from the data frame, unnecessary variable
df <- df[, -which(names(df) == "index")]

# Specifying the order of the first few columns for easier viewing (and the list of columns to exclude from the ROIs)
desired_order <- c("Subject_ID", "age", "sex", "site", "phenotype")

# Append the remaining column names that are not specified in desired_order
remaining_cols <- setdiff(names(df), desired_order)

# Combine the specified order with the remaining columns
new_order <- c(desired_order, remaining_cols)

# Reorder the columns in df according to new_order
df <- df[, new_order]

# Extract column names, remove those in desired_order, and remove z-score suffixes
ROI <- names(df)[!names(df) %in% desired_order & !grepl("_Z_predict", names(df))]

# Further clean the ROI names to ensure no duplicates from z-score names
ROI <- unique(gsub("_Z_predict", "", ROI))

# Recode phenotype variable
df$phenotype <- gsub("0", "MCI", df$phenotype)
df$phenotype <- gsub("1", "AD", df$phenotype)
df$phenotype <- as.factor(df$phenotype)
df$phenotype <- factor(df$phenotype, levels = c("MCI", "AD")) # explicitly set the reference level

# Recode site variable
df$site <- gsub("1", "GE", df$site)
df$site <- gsub("2", "Philips", df$site)
df$site <- gsub("3", "Siemens", df$site)
df$site <- as.factor(df$site)

# Recode sex variable, 0= females 1= males
df$sex <- gsub("0", "Female", df$sex)
df$sex <- gsub("1", "Male", df$sex)
df$sex <- factor(df$sex)

```

Identify and quantify outliers in brain region deviation scores by applying a defined statistical threshold, creating a binary representation for outlier detection, and summing these to obtain a total outlier score for each subject. The process includes visualizing these scores by phenotype and performing a basic regression analysis to examine the relationship between phenotypes and outlier scores, with additional summarization of the outlier distributions across phenotypes.

```{r Binarize Outliers, Create Total Outlier Score Across Total ROIs, and Brief Analyses, message=FALSE, warning=FALSE}
# Establish outlier threshold
outlier_threshold <- -1.96 # bottom 2.5%, as used in the Verdi et al., 2023 paper

# Apply threshold to z-score data to create dummy columns
df3 <- as.data.frame(ifelse(df[,6:153] < outlier_threshold,1,0))

# Rename all binarized columns to have the suffix "_bin"
df3 <- df3 %>% rename_all(paste0, "_bin")

# Sum the dummy column values to create a total outlier score
df$total_outlier_score <- rowSums(df3)

# Merge the two data frames
df <- cbind(df, df3)

# Remove df3 from your R environment as it's no longer needed
rm(df3)

# Create a group difference box plot with colored outlines and filled points
ggplot(df, aes(x = phenotype, y = total_outlier_score, color = phenotype, fill = phenotype)) +
  geom_boxplot(outlier.shape = NA, fill = NA, size = 1) +  # Draw box plots with no fill, only outlines
  geom_jitter(width = 0.2, size = 2, shape = 21) +  # Add jittered points with the same color
  labs(x = "Phenotype", y = "Total Outlier Score") +
  theme_minimal() +
  scale_color_manual(values=c("MCI" ="mediumturquoise", "AD"="lightslateblue")) +  # Color outline by phenotype
  scale_fill_manual(values=c("MCI" ="mediumturquoise", "AD"="lightslateblue")) +  # Fill points by phenotype
  theme(legend.position = "right")

# Calculate descriptives of total outlier score grouped by phenotype group
describeBy(df$total_outlier_score, df$phenotype, IQR = T)

# Basic regression analysis with phenoype as predictor and total outlier score as outcome
s1<- lm(total_outlier_score ~ phenotype, data = df)
tab_model(s1, show.ci = 0.95, title = "Linear Model: Total Outlier Score as a Function of Phenotype")

```

# ADNI vs PDC Preliminary Analyses {#adni-pdc}

------------------------------------------------------------------------

The code handles large data by segmenting regions into smaller subsets to prevent memory overload.

```{r PDC BLR vs HBR Preparation, message=FALSE, warning=FALSE}
# Merge datasets on SubjectID
merged_data <- inner_join(PDC_HBR, PDC_BLR, by = "SubjectID", suffix = c(".HBR", ".BLR"))

# Initialize a list to store all correlation results
all_correlation_results <- list()

# Define subsets of brain regions to avoid buffer overflow
brain_regions_1 <- c("L_G&S_frontomargin", "L_G&S_occipital_inf", "L_G&S_paracentral", 
                   "L_G&S_subcentral", "L_G&S_transv_frontopol", "L_G&S_cingul-Ant",
                   "L_G&S_cingul-Mid-Ant", "L_G&S_cingul-Mid-Post", "L_G_cingul-Post-dorsal",
                   "L_G_cingul-Post-ventral", "L_G_cuneus", "L_G_front_inf-Opercular", 
                   "L_G_front_inf-Orbital", "L_G_front_inf-Triangul", "L_G_front_middle")
brain_regions_2 <- c("L_G_front_sup", "L_G_Ins_lg&S_cent_ins", "L_G_insular_short", 
                   "L_G_occipital_middle", "L_G_occipital_sup", "L_G_oc-temp_lat-fusifor",
                   "L_G_oc-temp_med-Lingual", "L_G_oc-temp_med-Parahip", "L_G_orbital", 
                   "L_G_pariet_inf-Angular", "L_G_pariet_inf-Supramar", "L_G_parietal_sup", 
                   "L_G_postcentral", "L_G_precentral", "L_G_precuneus")
brain_regions_3 <- c("L_G_rectus", "L_G_subcallosal", "L_G_temp_sup-G_T_transv", "L_G_temp_sup-Lateral",
                   "L_G_temp_sup-Plan_polar", "L_G_temp_sup-Plan_tempo", "L_G_temporal_inf",
                   "L_G_temporal_middle", "L_Lat_Fis-ant-Horizont", "L_Lat_Fis-ant-Vertical",
                   "L_Lat_Fis-post", "L_Pole_occipital", "L_Pole_temporal", "L_S_calcarine", 
                   "L_S_central")
brain_regions_4 <- c("L_S_cingul-Marginalis", "L_S_circular_insula_ant",
                   "L_S_circular_insula_inf", "L_S_circular_insula_sup", "L_S_collat_transv_ant", 
                   "L_S_collat_transv_post", "L_S_front_inf", "L_S_front_middle", "L_S_front_sup", 
                   "L_S_interm_prim-Jensen", "L_S_intrapariet&P_trans", "L_S_oc_middle&Lunatus", 
                   "L_S_oc_sup&transversal", "L_S_occipital_ant", "L_S_oc-temp_lat")
brain_regions_5 <- c("L_S_oc-temp_med&Lingual", "L_S_orbital_lateral", "L_S_orbital_med-olfact", 
                   "L_S_orbital-H_Shaped", "L_S_parieto_occipital", "L_S_pericallosal", 
                   "L_S_postcentral", "L_S_precentral-inf-part", "L_S_precentral-sup-part", 
                   "L_S_suborbital", "L_S_subparietal", "L_S_temporal_inf", "L_S_temporal_sup", 
                   "L_S_temporal_transverse", "R_G&S_frontomargin")
brain_regions_6 <- c("R_G&S_occipital_inf", "R_G&S_paracentral", "R_G&S_subcentral", "R_G&S_transv_frontopol", 
                   "R_G&S_cingul-Ant", "R_G&S_cingul-Mid-Ant", "R_G&S_cingul-Mid-Post", 
                   "R_G_cingul-Post-dorsal", "R_G_cingul-Post-ventral", "R_G_cuneus", 
                   "R_G_front_inf-Opercular", "R_G_front_inf-Orbital", "R_G_front_inf-Triangul", 
                   "R_G_front_middle", "R_G_front_sup")
brain_regions_7 <- c("R_G_Ins_lg&S_cent_ins", "R_G_insular_short", "R_G_occipital_middle", "R_G_occipital_sup", 
                   "R_G_oc-temp_lat-fusifor", "R_G_oc-temp_med-Lingual", "R_G_oc-temp_med-Parahip", 
                   "R_G_orbital", "R_G_pariet_inf-Angular", "R_G_pariet_inf-Supramar", 
                   "R_G_parietal_sup", "R_G_postcentral", "R_G_precentral", "R_G_precuneus", 
                   "R_G_rectus")
brain_regions_8 <- c("R_G_subcallosal", "R_G_temp_sup-G_T_transv", "R_G_temp_sup-Lateral",
                   "R_G_temp_sup-Plan_polar", "R_G_temp_sup-Plan_tempo", "R_G_temporal_inf", 
                   "R_G_temporal_middle", "R_Lat_Fis-ant-Horizont", "R_Lat_Fis-ant-Vertical", 
                   "R_Lat_Fis-post", "R_Pole_occipital", "R_Pole_temporal", "R_S_calcarine", 
                   "R_S_central", "R_S_cingul-Marginalis")
brain_regions_9 <- c("R_S_circular_insula_ant", "R_S_circular_insula_inf", "R_S_circular_insula_sup", "R_S_collat_transv_ant", 
                   "R_S_collat_transv_post", "R_S_front_inf", "R_S_front_middle", "R_S_front_sup", 
                   "R_S_interm_prim-Jensen", "R_S_intrapariet&P_trans", "R_S_oc_middle&Lunatus", 
                   "R_S_oc_sup&transversal", "R_S_occipital_ant", "R_S_oc-temp_lat", 
                   "R_S_oc-temp_med&Lingual")
brain_regions_10 <- c("R_S_orbital_lateral", "R_S_orbital_med-olfact", 
                   "R_S_orbital-H_Shaped", "R_S_parieto_occipital", "R_S_pericallosal", 
                   "R_S_postcentral", "R_S_precentral-inf-part", "R_S_precentral-sup-part", 
                   "R_S_suborbital", "R_S_subparietal", "R_S_temporal_inf", "R_S_temporal_sup", 
                   "R_S_temporal_transverse")

# List to store all brain region subsets
brain_regions_list <- list(brain_regions_1, brain_regions_2, brain_regions_3, brain_regions_4, brain_regions_5, brain_regions_6, brain_regions_7, brain_regions_8, brain_regions_9, brain_regions_10)

```

Evaluate correlations between brain region deviation scores derived from hierarchical versus linear Bayesian regression models by merging relevant datasets and calculating Pearson correlation coefficients for predefined brain region subsets. Apply the **Benjamini-Hochberg** procedure to correct for multiple comparisons. The results are visualized using scatter and lollipop plots to highlight significant correlations across the brain regions, categorizing significance levels based on adjusted p-values.

::: callout-note
The Benjamini-Hochberg (BH) correction is employed in this analysis to adjust for multiple comparisons while maintaining a balance between identifying true associations and limiting false discoveries. This method controls the False Discovery Rate, which is particularly useful in large datasets with many hypotheses. Unlike more conservative methods, such as Bonferroni, which control for all types of errors collectively, the BH correction focuses on the proportion of errors among the rejected hypotheses, enhancing the ability to detect genuine effects without overly increasing the risk of Type I errors. This makes it highly suitable for complex data where tests are not independent, such as in correlation studies involving multiple regions or variables.
:::

```{r PDC BLR vs HBR Correlations and Visualizations, message=FALSE, warning=FALSE}
# Process each subset of brain regions
for (brain_regions in brain_regions_list) {
    correlation_results <- list()
    for(region in brain_regions) {
        region_hbr <- paste(region, ".HBR", sep = "")
        region_blr <- paste(region, ".BLR", sep = "")
        
        # Ensure both variables are present in the dataset
        if(region_hbr %in% names(merged_data) && region_blr %in% names(merged_data)) {
            # Use cor.test to get both correlation and p-value
            test_result <- cor.test(merged_data[[region_hbr]], merged_data[[region_blr]], 
                                    method = "pearson", use = "complete.obs")
            
            # Store results in a list
            correlation_results[[region]] <- list(
                Correlation = test_result$estimate,
                P_Value = test_result$p.value
            )
        }
    }
    # Add subset results to the master list
    all_correlation_results <- c(all_correlation_results, correlation_results)
}

# Convert the list to a data frame for easy viewing
correlation_df <- data.frame(
    Region = names(all_correlation_results),
    Correlation = sapply(all_correlation_results, function(x) x$Correlation),
    P_Value = sapply(all_correlation_results, function(x) x$P_Value),
    row.names = NULL
)

# Apply the Benjamini-Hochberg correction to the p-values
correlation_df$Adjusted_P_Value <- p.adjust(correlation_df$P_Value, method = "BH")

# Print the results
print(correlation_df)

# Convert the data to a suitable format for ggplot
correlation_df$Region <- factor(correlation_df$Region, levels = correlation_df$Region)

# Create a scatter plot for each region showing the correlation values
# Assuming 'merged_data' contains corresponding columns for HBR and BLR scores
ggplot(correlation_df, aes(x = Region, y = Correlation)) +
  geom_point(stat = "identity") +
  ylim(0.8, 1) +
  labs(title = "Correlation of Deviation Scores Across Brain Regions",
       x = "Brain Region", y = "Correlation Coefficient") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 5.5))

# Adding a new column for significance level based on p-values
correlation_df$Significance <- ifelse(correlation_df$Adjusted_P_Value < 0.001, '***',
                                      ifelse(correlation_df$Adjusted_P_Value < 0.01, '**',
                                      ifelse(correlation_df$Adjusted_P_Value < 0.05, '*', 'ns')))

# Create the lollipop plot
ggplot(correlation_df, aes(x = reorder(Region, Correlation), y = Correlation, color = Significance)) +
    geom_segment(aes(xend = Region, yend = 0.8), size = 0.25) +  # Create lines from 0 to the correlation value
    geom_point(size = 1) +  # Add points for each correlation value
    scale_color_manual(values = c('***' = 'red', '**' = 'orange', '*' = 'blue', 'ns' = 'grey')) +  # Assign colors based on significance
    labs(
        title = "Correlation and Significance of Brain Regions: Hierarchical vs. Linear Bayesian Regression",
        x = "Brain Region",
        y = "Correlation Coefficient",
        color = "Significance Level"
    ) +
    theme_minimal() +
    theme(
        legend.position = "top",  # Move the legend to the top of the plot
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 5.5),  # Improve readability of x-axis labels
        legend.title = element_text(face = "bold")  # Bold the legend title for emphasis
    )

```

Prepare two datasets (ADNI and PDC) by renaming variables, removing specific columns, and adding a study label. Combine these datasets and runs ANOVA tests to compare brain region deviation scores across studies, adjusting results for multiple comparisons using the FDR method. Significant results are highlighted and displayed.

```{r ADNI BLR vs PDC BLR ANOVA, message=FALSE, warning=FALSE}
# Rename ADNI data frame
ADNI_BLR <- df

# Rename SubjectID variable to Subject_ID for consistent merging
ADNI_BLR <- dplyr::rename(ADNI_BLR, SubjectID = "Subject_ID")

# Remove columns in the data frame ADNI_BLR that have names ending with "_bin"
ADNI_BLR <- ADNI_BLR[, !grepl("_bin$", names(ADNI_BLR))]

# Add a 'Study' column to each dataset to label the source
ADNI_BLR$Study <- 'ADNI'
ADNI_BLR$Study <- as.factor(ADNI_BLR$Study)
PDC_BLR$Study <- 'PDC'
PDC_BLR$Study <- as.factor(PDC_BLR$Study)

# Ensure brain_regions_list is a flattened vector if it's currently a list of lists
brain_regions_vector <- unlist(brain_regions_list)

# Subset the combined data to include only 'SubjectID', 'Study', and the brain region deviation scores
selected_columns <- c("SubjectID", "Study", brain_regions_vector)
ADNI_BLR <- ADNI_BLR[selected_columns]
PDC_BLR <- PDC_BLR[selected_columns]

# Combine the two datasets
ADNI_PDC <- bind_rows(ADNI_BLR, PDC_BLR)

# Initialize a list to store all ANOVA results
all_anova_results <- list()

# Loop through each brain region to perform ANOVA
for (region in brain_regions_vector) {
  # Correctly construct the formula using as.formula and paste
  formula_text <- paste("`", region, "` ~ Study", sep = "")
  formula <- as.formula(formula_text)
  model <- aov(formula, data = ADNI_PDC)
  # Extract the p-value
  p_value <- summary(model)[[1]][["Pr(>F)"]][1]
  all_anova_results[[region]] <- p_value
}

# Convert the list of p-values to a data frame
anova_df <- data.frame(
  ROI = names(all_anova_results),
  P_Value = unlist(all_anova_results),
  row.names = NULL
)

# Apply the FDR correction to the p-values
anova_df$FDR.pvalue <- p.adjust(anova_df$P_Value, method = "fdr")

# Optionally, print the adjusted p-values
print(anova_df)

# Identify regions where differences are significant at the adjusted p-value level (e.g., < 0.05)
significant_regions <- anova_df[anova_df$FDR.pvalue < 0.05, ]
print(significant_regions)

```

Refine brain region labels for visualization using a consistent nomenclature and display ANOVA results on hemisphere-specific plots, illustrating differences between ADNI and PDC studies with respect to deviation scores. Adjusted p-values are visualized using color gradients to denote significance levels.

```{r ANOVA Visualization, message=FALSE, warning=FALSE}
# Rename ROIs to assign nomenclature consistent with the desterieux atlas package
rename_rois <- function(df, hemi, desterieux_dims) {
  # Filter based on hemisphere
  hemi_prefix <- ifelse(hemi == "left", "L_", "R_")
  anova_df <- df %>%
    filter(str_detect(ROI, hemi_prefix))
  
  # Perform renaming steps
  x <- gsub(paste0(hemi_prefix), "", anova_df$ROI)
  patterns <- c("G&S_", "G_", "S_", "_", " bin", "\\.", "cingul ", "Mid ", "Post ", 
                "inf ", "med ", "sup ", "Fis ant ", "precentral ", "Fis pos ", "lg&S", 
                "oc temp", "sup and transversal", "orbital H Shaped", "oc sup&transversal", 
                "prim Jensen", "S oc-temp med&Lingual", "lat fusifor", "middle&Lunatus", 
                "intrapariet&P trans", "Lat Fis post")
  replacements <- c("G and S ", "G ", "S ", " ", "", " ", "cingul-", "Mid-", "Post-", 
                    "inf-", "med-", "sup-", "Fis-ant-", "precentral-", "Fis-pos-", 
                    "lg and S", "oc-temp", "sup-transversal", "orbital-H Shaped", 
                    "oc sup and transversal", "prim-Jensen", "S oc-temp med and Lingual", 
                    "lat-fusifor", "middle and Lunatus", "intrapariet and P trans", 
                    "Lat Fis-post")
  for (i in seq_along(patterns)) {
    x <- gsub(patterns[i], replacements[i], x)
  }
  
  # Match with desterieux ROIs
  desterieux_ROIs <- as.data.frame(desterieux_dims %>% filter(hemi == hemi))$region
  compare_lists <- cbind(sort(x), sort(unique(desterieux_ROIs)))
  list_matches <- compare_lists[,1] %in% compare_lists[,2]
  
  if (any(!list_matches)) {
    warning("There are mismatches in ROI names for the ", hemi, " hemisphere.")
  }
  
  anova_df$region <- x
  return(anova_df)
}

# Apply the function to each dataset and hemisphere
left_anova <- rename_rois(anova_df, "left", desterieux_dims)
right_anova <- rename_rois(anova_df, "right", desterieux_dims)

# Left hemisphere
left_pvalues <- ggseg(.data=left_anova, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "left", colour = "white", size = 0.2) + 
scale_fill_gradientn(limits = c(0,0.05), colours =  rainbow.colors(5))

# Right hemisphere
right_pvalues <- ggseg(.data=right_anova, atlas = desterieux, mapping=aes(fill=FDR.pvalue), hemisphere = "right", colour = "white", size = 0.2) +
  scale_fill_gradientn(limits = c(0,0.05), colours = rainbow.colors(5))

# Add titles to individual plots
left_pvalues <- left_pvalues + labs(title = "ADNI vs PDC ANOVA Results")
right_pvalues <- right_pvalues + labs(title = "ADNI vs PDC ANOVA Results")

# Combine plots for a comprehensive view
cowplot::plot_grid(left_pvalues, right_pvalues, nrow = 2)

```

```{r}

```

# Session Information {#session-information}

------------------------------------------------------------------------

To enhance **reproducibility**, details about the **working environment** used for these analyses can be found below.

```{r}
sessionInfo()
```
